var initializeModel = function(params) {

  // construct prior over possible misperceptions, based on version in params
  // 1. if 'none', there's no noise, and this prior is a delta on true context
  // 2. if 'random', then all possible corruptions are equally likely
  // 3. if 'similarityBased', then contexts closer to trueContext are more likely
  // Timeit note: this takes about 30ms for 'random' and 1000ms for 'similarityBased'
  var getNoisyContextPrior = function(trueContext) {
    return Infer({method: 'enumerate'}, function() {
      if(params.perceptualNoise === 'none') return trueContext;
      var context = (flip(1 - params.noiseRate) ? trueContext :
		     uniformDraw(uniqueContexts));
      factor(params.perceptualNoise === 'similarityBased' ?
	     similarity(trueContext, context) : 0);
      return context;
    });
  };
  
  // Cost of full utterances is sum of individual word costs,
  // unless you just use a color, in which case you incur
  // an additional costx
  var getUtteranceCost = function(utt) {
    var split = utt.split("_");
    if (split.length == 2) {
      return params.cost_color + params.cost_type;
    } else {
      return (_.contains(colors, split[0]) ?
	      params.cost_color + params.color_only_cost :
	      params.cost_type);
    }
  };

  // Looks up meaning in given lexicon
  // (if no entry, listener assigns vanishingly small probability)
  var meaning = function(utt, object) {
    var objStr = object.join("_");
    var lexicalEntry = params.lexicon[utt];
    return _.has(lexicalEntry, objStr) ? lexicalEntry[objStr] : -100; 
  };

  // Selects among objects in context using lexicon
  var literalListener = cache(function(utt, context){
    return Infer({method:'enumerate'},function(){
      var object = uniformDraw(context);
      factor(meaning(utt,object)); 
      return object;
    });
  });

  // Selects among utterances given informativity in context and cost of production,
  // marginalizing over possible noise in perception of context
  // Timeit note: marginalizing over listener takes about 200-300ms per utt
  var speaker = cache(function(target, context) {
    var possibleutts = getPossibleUtts(context);
    var noisyContextPrior = getNoisyContextPrior(context);
    return Infer({method:'enumerate'},function(){
      var utt = uniformDraw(possibleutts);
      var listener = Infer({method: 'enumerate'}, function() {
	var noisyContext = sample(noisyContextPrior);
	return sample(literalListener(utt, noisyContext));
      });
      factor(params.alpha * listener.score(target)
	     - getUtteranceCost(utt));
      return utt;
    });
  });

  return speaker;
};
